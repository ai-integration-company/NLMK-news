{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade --quiet  langchain langchain-community langchain-openai langchain-experimental neo4j wikipedia tiktoken yfiles_jupyter_graphs yandex_chain","metadata":{"execution":{"iopub.status.busy":"2024-06-10T14:25:09.635136Z","iopub.execute_input":"2024-06-10T14:25:09.635803Z","iopub.status.idle":"2024-06-10T14:26:17.260105Z","shell.execute_reply.started":"2024-06-10T14:25:09.635757Z","shell.execute_reply":"2024-06-10T14:26:17.258680Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkeras-cv 0.9.0 requires keras-core, which is not installed.\nkeras-nlp 0.12.1 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from langchain_core.runnables import (\n    RunnableBranch,\n    RunnableLambda,\n    RunnableParallel,\n    RunnablePassthrough,\n)\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.prompts.prompt import PromptTemplate\nfrom langchain_core.pydantic_v1 import BaseModel, Field\nfrom typing import Tuple, List, Optional\nfrom langchain_core.messages import AIMessage, HumanMessage\nfrom langchain_core.output_parsers import StrOutputParser\nimport os\nfrom langchain_community.graphs import Neo4jGraph\nfrom langchain.document_loaders import WikipediaLoader, WebBaseLoader\nfrom langchain.text_splitter import TokenTextSplitter\nfrom langchain_openai import ChatOpenAI\n#from langchain_experimental.graph_transformers import LLMGraphTransformer\nfrom neo4j import GraphDatabase\nfrom yfiles_jupyter_graphs import GraphWidget\nfrom langchain_community.vectorstores import Neo4jVector\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\nfrom langchain_core.runnables import ConfigurableField, RunnableParallel, RunnablePassthrough\nfrom yandex_chain import YandexEmbeddings\nfrom yandex_chain import YandexLLM\n\ntry:\n  import google.colab\n  from google.colab import output\n  output.enable_custom_widget_manager()\nexcept:\n  pass","metadata":{"execution":{"iopub.status.busy":"2024-06-10T14:26:17.263042Z","iopub.execute_input":"2024-06-10T14:26:17.263412Z","iopub.status.idle":"2024-06-10T14:26:20.071130Z","shell.execute_reply.started":"2024-06-10T14:26:17.263377Z","shell.execute_reply":"2024-06-10T14:26:20.069978Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"OPENAI_API_KEY = \"sk-proj-n89L3UTpqfnpvOirC63pT3BlbkFJr37jYXZnLWhl7wWKmvwM\"\nNEO4J_URI = \"neo4j+s://51f1d8ce.databases.neo4j.io\"\nNEO4J_USERNAME = \"neo4j\"\nNEO4J_PASSWORD = \"p0jzZN4FMxHVHgkErWZ6WaR-NCN12Exvxhves6vk19Y\"\n\ngraph = Neo4jGraph(url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T14:37:59.201841Z","iopub.execute_input":"2024-06-10T14:37:59.202328Z","iopub.status.idle":"2024-06-10T14:38:00.406435Z","shell.execute_reply.started":"2024-06-10T14:37:59.202292Z","shell.execute_reply":"2024-06-10T14:38:00.405357Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tags = ['AI', 'GPT', 'Yandex']\n\narr = [\n    {'date': '2023-06-01', 'link': 'https://habr.com/ru/articles/780008/', 'news_name': 'habr'},\n    {'date': '2023-06-02', 'link': 'https://www.rbc.ru/sport/09/06/2024/6665b86f9a79472a6485f52a?from=newsfeed', 'news_name': 'rbc'},\n    {'date': '2023-06-03', 'link': 'https://www.reddit.com/r/OpenAI/comments/187fzdb/openai_api_free_alternative_or_does_openai_api/', 'news_name': 'reddit'},\n]\n\ndocs = []\nfor i in arr:\n    doc = WebBaseLoader(i['link']).load()\n\n    doc[0].metadata['date'] = i['date']\n    doc[0].metadata['news_name'] = i['news_name']\n    docs.append(doc[0])","metadata":{"execution":{"iopub.status.busy":"2024-06-10T14:38:05.536281Z","iopub.execute_input":"2024-06-10T14:38:05.536705Z","iopub.status.idle":"2024-06-10T14:38:08.392303Z","shell.execute_reply.started":"2024-06-10T14:38:05.536672Z","shell.execute_reply":"2024-06-10T14:38:08.391116Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Define chunking strategy\ntext_splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=24)\ndocuments = text_splitter.split_documents(docs[0:])","metadata":{"execution":{"iopub.status.busy":"2024-06-10T14:38:08.394275Z","iopub.execute_input":"2024-06-10T14:38:08.394668Z","iopub.status.idle":"2024-06-10T14:38:08.416478Z","shell.execute_reply.started":"2024-06-10T14:38:08.394635Z","shell.execute_reply":"2024-06-10T14:38:08.415362Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"documents=documents[0:10]","metadata":{"execution":{"iopub.status.busy":"2024-06-10T14:38:08.418107Z","iopub.execute_input":"2024-06-10T14:38:08.418549Z","iopub.status.idle":"2024-06-10T14:38:08.424262Z","shell.execute_reply.started":"2024-06-10T14:38:08.418501Z","shell.execute_reply":"2024-06-10T14:38:08.423035Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"!pip install json-repair","metadata":{"execution":{"iopub.status.busy":"2024-06-10T14:38:08.426760Z","iopub.execute_input":"2024-06-10T14:38:08.427187Z","iopub.status.idle":"2024-06-10T14:38:24.048969Z","shell.execute_reply.started":"2024-06-10T14:38:08.427154Z","shell.execute_reply":"2024-06-10T14:38:24.047342Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Requirement already satisfied: json-repair in /opt/conda/lib/python3.10/site-packages (0.23.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"import asyncio\nimport json\nfrom typing import Any, Dict, List, Optional, Sequence, Tuple, Type, Union, cast\n\nfrom langchain_community.graphs.graph_document import GraphDocument, Node, Relationship\nfrom langchain_core.documents import Document\nfrom langchain_core.language_models import BaseLanguageModel\nfrom langchain_core.messages import SystemMessage\nfrom langchain_core.output_parsers import JsonOutputParser\nfrom langchain_core.prompts import (\n    ChatPromptTemplate,\n    HumanMessagePromptTemplate,\n    PromptTemplate,\n)\nfrom langchain_core.pydantic_v1 import BaseModel, Field, create_model\n\nexamples = [\n    {\n        \"text\": (\n            \"Adam is a software engineer in Microsoft since 2009, \"\n            \"and last year he got an award as the Best Talent\"\n        ),\n        \"head\": \"Adam\",\n        \"head_type\": \"Person\",\n        \"relation\": \"WORKS_FOR\",\n        \"tail\": \"Microsoft\",\n        \"tail_type\": \"Company\",\n    },\n    {\n        \"text\": (\n            \"Adam is a software engineer in Microsoft since 2009, \"\n            \"and last year he got an award as the Best Talent\"\n        ),\n        \"head\": \"Adam\",\n        \"head_type\": \"Person\",\n        \"relation\": \"HAS_AWARD\",\n        \"tail\": \"Best Talent\",\n        \"tail_type\": \"Award\",\n    },\n    {\n        \"text\": (\n            \"Microsoft is a tech company that provide \"\n            \"several products such as Microsoft Word\"\n        ),\n        \"head\": \"Microsoft Word\",\n        \"head_type\": \"Product\",\n        \"relation\": \"PRODUCED_BY\",\n        \"tail\": \"Microsoft\",\n        \"tail_type\": \"Company\",\n    },\n    {\n        \"text\": \"Microsoft Word is a lightweight app that accessible offline\",\n        \"head\": \"Microsoft Word\",\n        \"head_type\": \"Product\",\n        \"relation\": \"HAS_CHARACTERISTIC\",\n        \"tail\": \"accessible offline\",\n        \"tail_type\": \"Characteristic\",\n    },\n    {\n        \"text\": (\n            \"Ethereum smart contracts enable secure and automated transactions\"\n        ),\n        \"head\": \"smart contracts\",\n        \"head_type\": \"Technology\",\n        \"relation\": \"ENABLES\",\n        \"tail\": \"secure and automated transactions\",\n        \"tail_type\": \"Feature\",\n    },\n    {\n        \"text\": (\n            \"OpenAI's GPT-4 is a powerful language model used for various applications\"\n        ),\n        \"head\": \"GPT-4\",\n        \"head_type\": \"Product\",\n        \"relation\": \"PRODUCED_BY\",\n        \"tail\": \"OpenAI\",\n        \"tail_type\": \"Company\",\n    },\n    {\n        \"text\": (\n            \"Tesla is incorporating IoT to improve the performance of their electric vehicles\"\n        ),\n        \"head\": \"Tesla\",\n        \"head_type\": \"Company\",\n        \"relation\": \"USES_TECHNOLOGY\",\n        \"tail\": \"IoT\",\n        \"tail_type\": \"Technology\",\n    },\n    {\n        \"text\": (\n            \"Google's new AI system achieved state-of-the-art results in natural language processing\"\n        ),\n        \"head\": \"AI system\",\n        \"head_type\": \"Product\",\n        \"relation\": \"ACHIEVED\",\n        \"tail\": \"state-of-the-art results\",\n        \"tail_type\": \"Achievement\",\n    }\n]\n\nsystem_prompt = (\n    \"# Knowledge Graph Instructions for GPT-4\\n\"\n    \"## 1. Overview\\n\"\n    \"You are a top-tier algorithm designed for extracting information in structured \"\n    \"formats to build a knowledge graph.\\n\"\n    \"Try to capture as much information from the text as possible without \"\n    \"sacrifing accuracy. Do not add any information that is not explicitly \"\n    \"mentioned in the text\\n\"\n    \"- **Nodes** represent entities and concepts.\\n\"\n    \"- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\n\"\n    \"accessible for a vast audience.\\n\"\n    \"## 2. Labeling Nodes\\n\"\n    \"- **Consistency**: Ensure you use available types for node labels.\\n\"\n    \"Ensure you use basic or elementary types for node labels.\\n\"\n    \"- For example, when you identify an entity representing a person, \"\n    \"always label it as **'person'**. Avoid using more specific terms \"\n    \"like 'mathematician' or 'scientist'\"\n    \"  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be \"\n    \"names or human-readable identifiers found in the text.\\n\"\n    \"- **Relationships** represent connections between entities or concepts.\\n\"\n    \"Ensure consistency and generality in relationship types when constructing \"\n    \"knowledge graphs. Instead of using specific and momentary types \"\n    \"such as 'BECAME_PROFESSOR', use more general and timeless relationship types \"\n    \"like 'PROFESSOR'. Make sure to use general and timeless relationship types!\\n\"\n    \"## 3. Coreference Resolution\\n\"\n    \"- **Maintain Entity Consistency**: When extracting entities, it's vital to \"\n    \"ensure consistency.\\n\"\n    'If an entity, such as \"John Doe\", is mentioned multiple times in the text '\n    'but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),'\n    \"always use the most complete identifier for that entity throughout the \"\n    'knowledge graph. In this example, use \"John Doe\" as the entity ID.\\n'\n    \"Remember, the knowledge graph should be coherent and easily understandable, \"\n    \"so maintaining consistency in entity references is crucial.\\n\"\n    \"## 4. Strict Compliance\\n\"\n    \"Adhere to the rules strictly. Non-compliance will result in termination.\"\n)\n\ndefault_prompt = ChatPromptTemplate.from_messages(\n    [\n        (\n            \"system\",\n            system_prompt,\n        ),\n        (\n            \"human\",\n            (\n                \"Tip: Make sure to answer in the correct format and do \"\n                \"not include any explanations. \"\n                \"Use the given format to extract information from the \"\n                \"following input: {input}\"\n            ),\n        ),\n    ]\n)\n\n\ndef _get_additional_info(input_type: str) -> str:\n    # Check if the input_type is one of the allowed values\n    if input_type not in [\"node\", \"relationship\", \"property\"]:\n        raise ValueError(\"input_type must be 'node', 'relationship', or 'property'\")\n\n    # Perform actions based on the input_type\n    if input_type == \"node\":\n        return (\n            \"Ensure you use basic or elementary types for node labels.\\n\"\n            \"For example, when you identify an entity representing a person, \"\n            \"always label it as **'Person'**. Avoid using more specific terms \"\n            \"like 'Mathematician' or 'Scientist'\"\n        )\n    elif input_type == \"relationship\":\n        return (\n            \"Instead of using specific and momentary types such as \"\n            \"'BECAME_PROFESSOR', use more general and timeless relationship types like \"\n            \"'PROFESSOR'. However, do not sacrifice any accuracy for generality\"\n        )\n    elif input_type == \"property\":\n        return \"\"\n    return \"\"\n\n\ndef optional_enum_field(\n    enum_values: Optional[List[str]] = None,\n    description: str = \"\",\n    input_type: str = \"node\",\n    llm_type: Optional[str] = None,\n    **field_kwargs: Any,\n) -> Any:\n    \"\"\"Utility function to conditionally create a field with an enum constraint.\"\"\"\n    # Only openai supports enum param\n    if enum_values and llm_type == \"openai-chat\":\n        return Field(\n            ...,\n            enum=enum_values,\n            description=f\"{description}. Available options are {enum_values}\",\n            **field_kwargs,\n        )\n    elif enum_values:\n        return Field(\n            ...,\n            description=f\"{description}. Available options are {enum_values}\",\n            **field_kwargs,\n        )\n    else:\n        additional_info = _get_additional_info(input_type)\n        return Field(..., description=description + additional_info, **field_kwargs)\n\n\n\nclass _Graph(BaseModel):\n    nodes: Optional[List]\n    relationships: Optional[List]\n\n\nclass UnstructuredRelation(BaseModel):\n    head: str = Field(\n        description=(\n            \"extracted head entity like Microsoft, Apple, John. \"\n            \"Must use human-readable unique identifier.\"\n        )\n    )\n    head_type: str = Field(\n        description=\"type of the extracted head entity like Person, Company, etc\"\n    )\n    relation: str = Field(description=\"relation between the head and the tail entities\")\n    tail: str = Field(\n        description=(\n            \"extracted tail entity like Microsoft, Apple, John. \"\n            \"Must use human-readable unique identifier.\"\n        )\n    )\n    tail_type: str = Field(\n        description=\"type of the extracted tail entity like Person, Company, etc\"\n    )\n\n\n\ndef create_unstructured_prompt(\n    node_labels: Optional[List[str]] = None, rel_types: Optional[List[str]] = None\n) -> ChatPromptTemplate:\n    node_labels_str = str(node_labels) if node_labels else \"\"\n    rel_types_str = str(rel_types) if rel_types else \"\"\n    base_string_parts = [\n        \"You are a top-tier algorithm designed for extracting information in \"\n        \"structured formats to build a knowledge graph. Your task is to identify \"\n        \"the entities and relations requested with the user prompt from a given \"\n        \"text. You must generate the output in a JSON format containing a list \"\n        'with JSON objects. Each object should have the keys: \"head\", '\n        '\"head_type\", \"relation\", \"tail\", and \"tail_type\". The \"head\" '\n        \"key must contain the text of the extracted entity with one of the types \"\n        \"from the provided list in the user prompt.\",\n        f'The \"head_type\" key must contain the type of the extracted head entity, '\n        f\"which must be one of the types from {node_labels_str}.\"\n        if node_labels\n        else \"\",\n        f'The \"relation\" key must contain the type of relation between the \"head\" '\n        f'and the \"tail\", which must be one of the relations from {rel_types_str}.'\n        if rel_types\n        else \"\",\n        f'The \"tail\" key must represent the text of an extracted entity which is '\n        f'the tail of the relation, and the \"tail_type\" key must contain the type '\n        f\"of the tail entity from {node_labels_str}.\"\n        if node_labels\n        else \"\",\n        \"Attempt to extract as many entities and relations as you can. Maintain \"\n        \"Entity Consistency: When extracting entities, it's vital to ensure \"\n        'consistency. If an entity, such as \"John Doe\", is mentioned multiple '\n        \"times in the text but is referred to by different names or pronouns \"\n        '(e.g., \"Joe\", \"he\"), always use the most complete identifier for '\n        \"that entity. The knowledge graph should be coherent and easily \"\n        \"understandable, so maintaining consistency in entity references is \"\n        \"crucial.\",\n        \"IMPORTANT NOTES:\\n- Don't add any explanation and text. Translate text if language is not English.\",\n    ]\n    system_prompt = \"\\n\".join(filter(None, base_string_parts))\n\n    system_message = SystemMessage(content=system_prompt)\n    parser = JsonOutputParser(pydantic_object=UnstructuredRelation)\n\n    human_prompt = PromptTemplate(\n        template=\"\"\"Based on the following example, extract entities and \nrelations from the provided text.\\n\\n\nUse the following entity types, don't use other entity that is not defined below:\n# ENTITY TYPES:\n{node_labels}\n\nUse the following relation types, don't use other relation that is not defined below:\n# RELATION TYPES:\n{rel_types}\n\nBelow are a number of examples of text and their extracted entities and relationships.\n{examples}\n\nFor the following text, extract entities and relations as in the provided example.\n{format_instructions}\\nText: {input}\"\"\",\n        input_variables=[\"input\"],\n        partial_variables={\n            \"format_instructions\": parser.get_format_instructions(),\n            \"node_labels\": node_labels,\n            \"rel_types\": rel_types,\n            \"examples\": examples,\n        },\n    )\n\n    human_message_prompt = HumanMessagePromptTemplate(prompt=human_prompt)\n\n    chat_prompt = ChatPromptTemplate.from_messages(\n        [system_message, human_message_prompt]\n    )\n    return chat_prompt\n\n\n\ndef create_simple_model(\n    node_labels: Optional[List[str]] = None,\n    rel_types: Optional[List[str]] = None,\n    node_properties: Union[bool, List[str]] = False,\n    llm_type: Optional[str] = None,\n) -> Type[_Graph]:\n    \"\"\"\n    Simple model allows to limit node and/or relationship types.\n    Doesn't have any node or relationship properties.\n    \"\"\"\n\n    node_fields: Dict[str, Tuple[Any, Any]] = {\n        \"id\": (\n            str,\n            Field(..., description=\"Name or human-readable unique identifier.\"),\n        ),\n        \"type\": (\n            str,\n            optional_enum_field(\n                node_labels,\n                description=\"The type or label of the node.\",\n                input_type=\"node\",\n                llm_type=llm_type,\n            ),\n        ),\n    }\n    if node_properties:\n        if isinstance(node_properties, list) and \"id\" in node_properties:\n            raise ValueError(\"The node property 'id' is reserved and cannot be used.\")\n        # Map True to empty array\n        node_properties_mapped: List[str] = (\n            [] if node_properties is True else node_properties\n        )\n\n        class Property(BaseModel):\n            \"\"\"A single property consisting of key and value\"\"\"\n\n            key: str = optional_enum_field(\n                node_properties_mapped,\n                description=\"Property key.\",\n                input_type=\"property\",\n            )\n            value: str = Field(..., description=\"value\")\n\n        node_fields[\"properties\"] = (\n            Optional[List[Property]],\n            Field(None, description=\"List of node properties\"),\n        )\n    SimpleNode = create_model(\"SimpleNode\", **node_fields)  # type: ignore\n\n    class SimpleRelationship(BaseModel):\n        \"\"\"Represents a directed relationship between two nodes in a graph.\"\"\"\n\n        source_node_id: str = Field(\n            description=\"Name or human-readable unique identifier of source node\"\n        )\n        source_node_type: str = optional_enum_field(\n            node_labels,\n            description=\"The type or label of the source node.\",\n            input_type=\"node\",\n            llm_type=llm_type,\n        )\n        target_node_id: str = Field(\n            description=\"Name or human-readable unique identifier of target node\"\n        )\n        target_node_type: str = optional_enum_field(\n            node_labels,\n            description=\"The type or label of the target node.\",\n            input_type=\"node\",\n            llm_type=llm_type,\n        )\n        type: str = optional_enum_field(\n            rel_types,\n            description=\"The type of the relationship.\",\n            input_type=\"relationship\",\n            llm_type=llm_type,\n        )\n\n    class DynamicGraph(_Graph):\n        \"\"\"Represents a graph document consisting of nodes and relationships.\"\"\"\n\n        nodes: Optional[List[SimpleNode]] = Field(description=\"List of nodes\")  # type: ignore\n        relationships: Optional[List[SimpleRelationship]] = Field(\n            description=\"List of relationships\"\n        )\n\n    return DynamicGraph\n\n\n\ndef map_to_base_node(node: Any) -> Node:\n    \"\"\"Map the SimpleNode to the base Node.\"\"\"\n    properties = {}\n    if hasattr(node, \"properties\") and node.properties:\n        for p in node.properties:\n            properties[format_property_key(p.key)] = p.value\n    return Node(id=node.id, type=node.type, properties=properties)\n\n\n\ndef map_to_base_relationship(rel: Any) -> Relationship:\n    \"\"\"Map the SimpleRelationship to the base Relationship.\"\"\"\n    source = Node(id=rel.source_node_id, type=rel.source_node_type)\n    target = Node(id=rel.target_node_id, type=rel.target_node_type)\n    return Relationship(source=source, target=target, type=rel.type)\n\n\n\ndef _parse_and_clean_json(\n    argument_json: Dict[str, Any],\n) -> Tuple[List[Node], List[Relationship]]:\n    nodes = []\n    for node in argument_json[\"nodes\"]:\n        if not node.get(\"id\"):  # Id is mandatory, skip this node\n            continue\n        nodes.append(\n            Node(\n                id=node[\"id\"],\n                type=node.get(\"type\"),\n            )\n        )\n    relationships = []\n    for rel in argument_json[\"relationships\"]:\n        # Mandatory props\n        if (\n            not rel.get(\"source_node_id\")\n            or not rel.get(\"target_node_id\")\n            or not rel.get(\"type\")\n        ):\n            continue\n\n        # Node type copying if needed from node list\n        if not rel.get(\"source_node_type\"):\n            try:\n                rel[\"source_node_type\"] = [\n                    el.get(\"type\")\n                    for el in argument_json[\"nodes\"]\n                    if el[\"id\"] == rel[\"source_node_id\"]\n                ][0]\n            except IndexError:\n                rel[\"source_node_type\"] = None\n        if not rel.get(\"target_node_type\"):\n            try:\n                rel[\"target_node_type\"] = [\n                    el.get(\"type\")\n                    for el in argument_json[\"nodes\"]\n                    if el[\"id\"] == rel[\"target_node_id\"]\n                ][0]\n            except IndexError:\n                rel[\"target_node_type\"] = None\n\n        source_node = Node(\n            id=rel[\"source_node_id\"],\n            type=rel[\"source_node_type\"],\n        )\n        target_node = Node(\n            id=rel[\"target_node_id\"],\n            type=rel[\"target_node_type\"],\n        )\n        relationships.append(\n            Relationship(\n                source=source_node,\n                target=target_node,\n                type=rel[\"type\"],\n            )\n        )\n    return nodes, relationships\n\n\ndef _format_nodes(nodes: List[Node]) -> List[Node]:\n    return [\n        Node(\n            id=el.id.title() if isinstance(el.id, str) else el.id,\n            type=el.type.capitalize(),\n            properties=el.properties,\n        )\n        for el in nodes\n    ]\n\n\ndef _format_relationships(rels: List[Relationship]) -> List[Relationship]:\n    return [\n        Relationship(\n            source=_format_nodes([el.source])[0],\n            target=_format_nodes([el.target])[0],\n            type=el.type.replace(\" \", \"_\").upper(),\n        )\n        for el in rels\n    ]\n\n\ndef format_property_key(s: str) -> str:\n    words = s.split()\n    if not words:\n        return s\n    first_word = words[0].lower()\n    capitalized_words = [word.capitalize() for word in words[1:]]\n    return \"\".join([first_word] + capitalized_words)\n\n\n\ndef _convert_to_graph_document(\n    raw_schema: Dict[Any, Any],\n) -> Tuple[List[Node], List[Relationship]]:\n    # If there are validation errors\n    if not raw_schema[\"parsed\"]:\n        try:\n            try:  # OpenAI type response\n                argument_json = json.loads(\n                    raw_schema[\"raw\"].additional_kwargs[\"tool_calls\"][0][\"function\"][\n                        \"arguments\"\n                    ]\n                )\n            except Exception:  # Google type response\n                argument_json = json.loads(\n                    raw_schema[\"raw\"].additional_kwargs[\"function_call\"][\"arguments\"]\n                )\n\n            nodes, relationships = _parse_and_clean_json(argument_json)\n        except Exception:  # If we can't parse JSON\n            return ([], [])\n    else:  # If there are no validation errors use parsed pydantic object\n        parsed_schema: _Graph = raw_schema[\"parsed\"]\n        nodes = (\n            [map_to_base_node(node) for node in parsed_schema.nodes]\n            if parsed_schema.nodes\n            else []\n        )\n\n        relationships = (\n            [map_to_base_relationship(rel) for rel in parsed_schema.relationships]\n            if parsed_schema.relationships\n            else []\n        )\n    # Title / Capitalize\n    return _format_nodes(nodes), _format_relationships(relationships)\n\n\nclass MYLLMGraphTransformer:\n    \"\"\"Transform documents into graph-based documents using a LLM.\n\n    It allows specifying constraints on the types of nodes and relationships to include\n    in the output graph. The class doesn't support neither extract and node or\n    relationship properties\n\n    Args:\n        llm (BaseLanguageModel): An instance of a language model supporting structured\n          output.\n        allowed_nodes (List[str], optional): Specifies which node types are\n          allowed in the graph. Defaults to an empty list, allowing all node types.\n        allowed_relationships (List[str], optional): Specifies which relationship types\n          are allowed in the graph. Defaults to an empty list, allowing all relationship\n          types.\n        prompt (Optional[ChatPromptTemplate], optional): The prompt to pass to\n          the LLM with additional instructions.\n        strict_mode (bool, optional): Determines whether the transformer should apply\n          filtering to strictly adhere to `allowed_nodes` and `allowed_relationships`.\n          Defaults to True.\n\n    Example:\n        .. code-block:: python\n            from langchain_experimental.graph_transformers import LLMGraphTransformer\n            from langchain_core.documents import Document\n            from langchain_openai import ChatOpenAI\n\n            llm=ChatOpenAI(temperature=0)\n            transformer = LLMGraphTransformer(\n                llm=llm,\n                allowed_nodes=[\"Person\", \"Organization\"])\n\n            doc = Document(page_content=\"Elon Musk is suing OpenAI\")\n            graph_documents = transformer.convert_to_graph_documents([doc])\n    \"\"\"\n\n    def __init__(\n        self,\n        llm: BaseLanguageModel,\n        allowed_nodes: List[str] = [],\n        allowed_relationships: List[str] = [],\n        prompt: Optional[ChatPromptTemplate] = None,\n        strict_mode: bool = True,\n        node_properties: Union[bool, List[str]] = False,\n    ) -> None:\n        self.allowed_nodes = allowed_nodes\n        self.allowed_relationships = allowed_relationships\n        self.strict_mode = strict_mode\n        self._function_call = True\n        # Check if the LLM really supports structured output\n        try:\n            llm.with_structured_output(_Graph)\n        except NotImplementedError:\n            self._function_call = False\n        if not self._function_call:\n            if node_properties:\n                raise ValueError(\n                    \"The 'node_properties' parameter cannot be used \"\n                    \"in combination with a LLM that doesn't support \"\n                    \"native function calling.\"\n                )\n            try:\n                import json_repair\n\n                self.json_repair = json_repair\n            except ImportError:\n                raise ImportError(\n                    \"Could not import json_repair python package. \"\n                    \"Please install it with `pip install json-repair`.\"\n                )\n            prompt = prompt or create_unstructured_prompt(\n                allowed_nodes, allowed_relationships\n            )\n            print(prompt)\n            self.chain = prompt | llm\n        else:\n            # Define chain\n            try:\n                llm_type = llm._llm_type  # type: ignore\n            except AttributeError:\n                llm_type = None\n            schema = create_simple_model(\n                allowed_nodes, allowed_relationships, node_properties, llm_type\n            )\n            structured_llm = llm.with_structured_output(schema, include_raw=True)\n            prompt = prompt or default_prompt\n            print(prompt)\n            self.chain = prompt | structured_llm\n\n\n    def process_response(self, document: Document) -> GraphDocument:\n        \"\"\"\n        Processes a single document, transforming it into a graph document using\n        an LLM based on the model's schema and constraints.\n        \"\"\"\n        text = document.page_content\n        raw_schema = self.chain.invoke({\"input\": text})\n        if self._function_call:\n            raw_schema = cast(Dict[Any, Any], raw_schema)\n            nodes, relationships = _convert_to_graph_document(raw_schema)\n        else:\n            nodes_set = set()\n            relationships = []\n            if not isinstance(raw_schema, str):\n                raw_schema = raw_schema.content\n            parsed_json = self.json_repair.loads(raw_schema)\n            \n            for rel in parsed_json:\n                print(rel)\n                # Nodes need to be deduplicated using a set\n                nodes_set.add((rel[\"head\"], rel[\"head_type\"]))\n                nodes_set.add((rel[\"tail\"], rel[\"tail_type\"]))\n\n                source_node = Node(id=rel[\"head\"], type=rel[\"head_type\"])\n                target_node = Node(id=rel[\"tail\"], type=rel[\"tail_type\"])\n                relationships.append(\n                    Relationship(\n                        source=source_node, target=target_node, type=rel[\"relation\"]\n                    )\n                )\n            # Create nodes list\n            nodes = [Node(id=el[0], type=el[1]) for el in list(nodes_set)]\n\n        # Strict mode filtering\n        if self.strict_mode and (self.allowed_nodes or self.allowed_relationships):\n            if self.allowed_nodes:\n                lower_allowed_nodes = [el.lower() for el in self.allowed_nodes]\n                nodes = [\n                    node for node in nodes if node.type.lower() in lower_allowed_nodes\n                ]\n                relationships = [\n                    rel\n                    for rel in relationships\n                    if rel.source.type.lower() in lower_allowed_nodes\n                    and rel.target.type.lower() in lower_allowed_nodes\n                ]\n            if self.allowed_relationships:\n                relationships = [\n                    rel\n                    for rel in relationships\n                    if rel.type.lower()\n                    in [el.lower() for el in self.allowed_relationships]\n                ]\n\n        return GraphDocument(nodes=nodes, relationships=relationships, source=document)\n\n\n    def convert_to_graph_documents(\n        self, documents: Sequence[Document]\n    ) -> List[GraphDocument]:\n        \"\"\"Convert a sequence of documents into graph documents.\n\n        Args:\n            documents (Sequence[Document]): The original documents.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            Sequence[GraphDocument]: The transformed documents as graphs.\n        \"\"\"\n        return [self.process_response(document) for document in documents]\n\n\n    async def aprocess_response(self, document: Document) -> GraphDocument:\n        \"\"\"\n        Asynchronously processes a single document, transforming it into a\n        graph document.\n        \"\"\"\n        text = document.page_content\n        raw_schema = await self.chain.ainvoke({\"input\": text})\n        raw_schema = cast(Dict[Any, Any], raw_schema)\n        nodes, relationships = _convert_to_graph_document(raw_schema)\n\n        if self.strict_mode and (self.allowed_nodes or self.allowed_relationships):\n            if self.allowed_nodes:\n                lower_allowed_nodes = [el.lower() for el in self.allowed_nodes]\n                nodes = [\n                    node for node in nodes if node.type.lower() in lower_allowed_nodes\n                ]\n                relationships = [\n                    rel\n                    for rel in relationships\n                    if rel.source.type.lower() in lower_allowed_nodes\n                    and rel.target.type.lower() in lower_allowed_nodes\n                ]\n            if self.allowed_relationships:\n                relationships = [\n                    rel\n                    for rel in relationships\n                    if rel.type.lower()\n                    in [el.lower() for el in self.allowed_relationships]\n                ]\n\n        return GraphDocument(nodes=nodes, relationships=relationships, source=document)\n\n\n    async def aconvert_to_graph_documents(\n        self, documents: Sequence[Document]\n    ) -> List[GraphDocument]:\n        \"\"\"\n        Asynchronously convert a sequence of documents into graph documents.\n        \"\"\"\n        tasks = [\n            asyncio.create_task(self.aprocess_response(document))\n            for document in documents\n        ]\n        results = await asyncio.gather(*tasks)\n        return results\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T14:38:24.052208Z","iopub.execute_input":"2024-06-10T14:38:24.052754Z","iopub.status.idle":"2024-06-10T14:38:24.160842Z","shell.execute_reply.started":"2024-06-10T14:38:24.052703Z","shell.execute_reply":"2024-06-10T14:38:24.159385Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"llmg=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-0125\", api_key=OPENAI_API_KEY) # gpt-4-0125-preview occasionally has issues\n\nFOLDER_ID=\"b1ghpjs6kvfc7th9878i\"\nAPI_KEY=\"AQVN3cYT0g9maVmBps--HVvRr7t6dPNdR4NL3eDo\"\n\nembeddings = YandexEmbeddings(\n    folder_id=FOLDER_ID, api_key=API_KEY,\n)\n\nllm = YandexLLM(folder_id=FOLDER_ID, api_key=API_KEY)\n\nllm_transformer = MYLLMGraphTransformer(llm=llmg)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T14:38:24.163127Z","iopub.execute_input":"2024-06-10T14:38:24.163665Z","iopub.status.idle":"2024-06-10T14:38:24.209410Z","shell.execute_reply.started":"2024-06-10T14:38:24.163615Z","shell.execute_reply":"2024-06-10T14:38:24.208004Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"input_variables=['input'] messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))]\n","output_type":"stream"}]},{"cell_type":"code","source":"graph_documents = llm_transformer.convert_to_graph_documents(documents)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T14:38:57.717165Z","iopub.execute_input":"2024-06-10T14:38:57.717639Z","iopub.status.idle":"2024-06-10T14:39:32.496294Z","shell.execute_reply.started":"2024-06-10T14:38:57.717572Z","shell.execute_reply":"2024-06-10T14:39:32.495109Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print(graph_documents)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T14:39:43.306208Z","iopub.execute_input":"2024-06-10T14:39:43.306644Z","iopub.status.idle":"2024-06-10T14:39:43.316656Z","shell.execute_reply.started":"2024-06-10T14:39:43.306604Z","shell.execute_reply":"2024-06-10T14:39:43.315394Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"[GraphDocument(nodes=[Node(id='Yandex Gpt', type='Technology'), Node(id='Python', type='Programming language')], relationships=[Relationship(source=Node(id='Yandex Gpt', type='Technology'), target=Node(id='Python', type='Programming language'), type='USAGE')], source=Document(page_content='\\n\\n\\nКак подключить Yandex GPT к своему проекту на Python / Хабр\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nХабрβОткрыть списокКак стать авторомМоя лентаВсе потокиРазработкаАдминистрированиеДизайнМенеджментМаркетингНаучпопПоискНаписать публикациюНастройкиВойтиОбновитьSKarulin 12  дек  2023 в 12:23Как подключить Yandex GPT к своему проекту на PythonУровень сложностиПростойВремя на прочтение4 минКоличество просмотров33KPython*Яндекс API*Из песочницы6 декабря Яндекс открыл доступ к своим диалоговым моделям (модел', metadata={'source': 'https://habr.com/ru/articles/780008/', 'title': 'Как подключить Yandex GPT к своему проекту на Python / Хабр', 'description': '6 декабря Яндекс открыл доступ к своим диалоговым моделям (моделям генерации) и векторного представления текста через API. API уже доступно в Yandex Cloud. Вчера мне потребовалось применить его в...', 'language': 'ru', 'date': '2023-06-01', 'news_name': 'habr'})), GraphDocument(nodes=[Node(id='Dialog_Models', type='Model'), Node(id='Text_Representation', type='Model'), Node(id='Yandex_Cloud', type='Api')], relationships=[Relationship(source=Node(id='Dialog_Models', type='Model'), target=Node(id='Yandex_Cloud', type='Api'), type='USES'), Relationship(source=Node(id='Text_Representation', type='Model'), target=Node(id='Yandex_Cloud', type='Api'), type='USES')], source=Document(page_content='�иалоговым моделям (моделям генерации) и векторного представления текста через API. API уже доступно в Yandex Cloud. Вчера мне потребовалось применить его в приложении, однако не удалось найти руководства, как сделать это быстро. Документация Яндекса хороша, но предполагает, что опыт работы с Yandex Cloud уже имеется. В отсутствие такого опыта документация выглядит фрагментированной.Предлагаю пошаговый гайд, который, надеюсь, сэкономит читателю, не знакомому с Yandex Cloud, часик-другой.Для того, чтоб', metadata={'source': 'https://habr.com/ru/articles/780008/', 'title': 'Как подключить Yandex GPT к своему проекту на Python / Хабр', 'description': '6 декабря Яндекс открыл доступ к своим диалоговым моделям (моделям генерации) и векторного представления текста через API. API уже доступно в Yandex Cloud. Вчера мне потребовалось применить его в...', 'language': 'ru', 'date': '2023-06-01', 'news_name': 'habr'})), GraphDocument(nodes=[Node(id='Yandex Gpt', type='Tool'), Node(id='Python', type='Programming language'), Node(id='Yandex Id', type='Identifier'), Node(id='Yandex Cloud', type='Service'), Node(id='Api', type='Interface')], relationships=[Relationship(source=Node(id='Yandex Gpt', type='Tool'), target=Node(id='Yandex Id', type='Identifier'), type='REQUIRES'), Relationship(source=Node(id='Yandex Gpt', type='Tool'), target=Node(id='Python', type='Programming language'), type='REQUIRES'), Relationship(source=Node(id='Yandex Cloud', type='Service'), target=Node(id='Yandex Gpt', type='Tool'), type='REQUIRES'), Relationship(source=Node(id='Yandex Cloud', type='Service'), target=Node(id='Yandex Id', type='Identifier'), type='REQUIRES'), Relationship(source=Node(id='Api', type='Interface'), target=Node(id='Python', type='Programming language'), type='REQUIRES')], source=Document(page_content='другой.Для того, чтобы использовать Yandex GPT в Вашем Python-проекте, нужно выполнить 4 шага:Создать Яндекс ID (например, зарегистрировавшися в Яндекс.Почте).Подключить средство оплаты в Yandex Cloud и при необходимости пополнить баланс.Получить ключ авторизации и идентификатор каталога.Создать Python файл, реализующий взаимодействие с API.Создаём Яндекс IDРегистрироваться удобно по номеру телефона. Процесс не должен вызывать затруднений: просто перейдите по ссылке и следуйте инструкциям систе', metadata={'source': 'https://habr.com/ru/articles/780008/', 'title': 'Как подключить Yandex GPT к своему проекту на Python / Хабр', 'description': '6 декабря Яндекс открыл доступ к своим диалоговым моделям (моделям генерации) и векторного представления текста через API. API уже доступно в Yandex Cloud. Вчера мне потребовалось применить его в...', 'language': 'ru', 'date': '2023-06-01', 'news_name': 'habr'})), GraphDocument(nodes=[Node(id='Yandex Gpt Api', type='Service'), Node(id='Yandex Cloud', type='Service'), Node(id='Yandex Cloud Billing', type='Service')], relationships=[Relationship(source=Node(id='Yandex Gpt Api', type='Service'), target=Node(id='Yandex Cloud', type='Service'), type='USES'), Relationship(source=Node(id='Yandex Cloud', type='Service'), target=Node(id='Yandex Cloud Billing', type='Service'), type='BILLING')], source=Document(page_content='уйте инструкциям системы до получения аккаунта.Подключаем средство оплаты и пополняем балансYandex GPT API - платный сервис Yandex Cloud. Ознакомиться с тарифами можно здесь.Для получения доступа перейдите в консоль. Система предложит создать облако, выбрав (или создав) организацию и подтвердив название облака. Создаём.Оказавшись в консоли, Вы увидите структуру каталогов слева. А еще левее - кнопку вызова меню \"Все сервисы\", по нажатии на которую открывается список сервисов. Выберите Yandex Cloud Billing.Yandex Cloud Bill', metadata={'source': 'https://habr.com/ru/articles/780008/', 'title': 'Как подключить Yandex GPT к своему проекту на Python / Хабр', 'description': '6 декабря Яндекс открыл доступ к своим диалоговым моделям (моделям генерации) и векторного представления текста через API. API уже доступно в Yandex Cloud. Вчера мне потребовалось применить его в...', 'language': 'ru', 'date': '2023-06-01', 'news_name': 'habr'})), GraphDocument(nodes=[Node(id='Yandex Cloud Billing', type='Service'), Node(id='Yandex Cloud Billing Console', type='Interface'), Node(id='Plastic Card', type='Payment method'), Node(id='Vpn', type='Service')], relationships=[Relationship(source=Node(id='Yandex Cloud Billing', type='Service'), target=Node(id='Yandex Cloud Billing Console', type='Interface'), type='ACCESS_INSTRUCTIONS'), Relationship(source=Node(id='Yandex Cloud Billing Console', type='Interface'), target=Node(id='Plastic Card', type='Payment method'), type='REQUIRES'), Relationship(source=Node(id='Plastic Card', type='Payment method'), target=Node(id='Vpn', type='Service'), type='BETTER_TO_DISABLE'), Relationship(source=Node(id='Yandex Cloud Billing Console', type='Interface'), target=Node(id='Plastic Card', type='Payment method'), type='REQUIRES'), Relationship(source=Node(id='Yandex Cloud Billing Console', type='Interface'), target=Node(id='Plastic Card', type='Payment method'), type='REQUIRES'), Relationship(source=Node(id='Yandex Cloud Billing Console', type='Interface'), target=Node(id='Plastic Card', type='Payment method'), type='REQUIRES'), Relationship(source=Node(id='Yandex Cloud Billing Console', type='Interface'), target=Node(id='Plastic Card', type='Payment method'), type='REQUIRES')], source=Document(page_content='�. Выберите Yandex Cloud Billing.Yandex Cloud Billing в меню \"Все сервисы\"В консоли Yandex Cloud Billing нажмите \"Создать\". Процесс создания аккаунта прост, но потребует привязки пластиковой карты. При привязке карты VPN лучше отключить.После нажатия кнопки \"Создать\" в зависимости о того, создавали ли Вы ранее платежные аккаунты, система либо предоставит аккаунт пополненный стартовым грантом, либо предоставит пустой аккаунт. В этом случае нужно воспользоваться кнопкой \"Пополнить баланс\" справа. Минимальная сумма пополнения на сег', metadata={'source': 'https://habr.com/ru/articles/780008/', 'title': 'Как подключить Yandex GPT к своему проекту на Python / Хабр', 'description': '6 декабря Яндекс открыл доступ к своим диалоговым моделям (моделям генерации) и векторного представления текста через API. API уже доступно в Yandex Cloud. Вчера мне потребовалось применить его в...', 'language': 'ru', 'date': '2023-06-01', 'news_name': 'habr'})), GraphDocument(nodes=[Node(id='500 Рублей', type='Amount'), Node(id='Api Ключ', type='Authorization key'), Node(id='Сервисный Аккаунт', type='Service account'), Node(id='Главная Страница Консоли', type='Console main page'), Node(id='Default', type='Menu folder'), Node(id='Ai.Languagemodels.User', type='Role')], relationships=[Relationship(source=Node(id='500 Рублей', type='Amount'), target=Node(id='Api Ключ', type='Authorization key'), type='AUTHORIZATION_KEY_GENERATION'), Relationship(source=Node(id='Api Ключ', type='Authorization key'), target=Node(id='Сервисный Аккаунт', type='Service account'), type='AUTHORIZATION_METHOD:_API_KEY'), Relationship(source=Node(id='Главная Страница Консоли', type='Console main page'), target=Node(id='Default', type='Menu folder'), type='ACCESS_VIA_MENU'), Relationship(source=Node(id='Default', type='Menu folder'), target=Node(id='Сервисный Аккаунт', type='Service account'), type='SERVICE_ACCOUNT_CREATION'), Relationship(source=Node(id='Сервисный Аккаунт', type='Service account'), target=Node(id='Ai.Languagemodels.User', type='Role'), type='ROLE_ASSIGNMENT:_AI.LANGUAGEMODELS.USER')], source=Document(page_content='сумма пополнения на сегодняшний день 500 рублей.Получаем ключ авторизацииСамым простым способом авторизации мне показалась авторизации по API ключу. Для его получения необходимо создать сервисный аккаунт.Для этого:Вернитесь на главную страницу консоли через меню слева.Кнопка возврата на главную страницу консолиСоздайте сервисный аккаунт через меню папки default.При создании сервисного аккаунта назначьте роль \"ai.languageModels.user\".Создание сервисного аккаунтаВ результате Вы попадёте на ', metadata={'source': 'https://habr.com/ru/articles/780008/', 'title': 'Как подключить Yandex GPT к своему проекту на Python / Хабр', 'description': '6 декабря Яндекс открыл доступ к своим диалоговым моделям (моделям генерации) и векторного представления текста через API. API уже доступно в Yandex Cloud. Вчера мне потребовалось применить его в...', 'language': 'ru', 'date': '2023-06-01', 'news_name': 'habr'})), GraphDocument(nodes=[Node(id='Default', type='Catalog'), Node(id='Default-Service', type='Service account')], relationships=[Relationship(source=Node(id='Default', type='Catalog'), target=Node(id='Default-Service', type='Service account'), type='HAS_SERVICE_ACCOUNT')], source=Document(page_content='ультате Вы попадёте на страницу каталога default, но, если этого не произошло, просто выберите default в дереве каталогов слева. Сразу скопируйте идентификатор каталога из строки навигации сверху. Он понадобится при написании скрипта наряду с API-ключом, который мы получим далее.Расположение идентификатора каталога и вкладки \"Сервисные аккаунты\" в консолиНиже на странице каталога default выберите вкладку \"Сервисные аккаунты\", а там кликните на вновь созданный аккаунт, в моём случае default-service.В меню навигац', metadata={'source': 'https://habr.com/ru/articles/780008/', 'title': 'Как подключить Yandex GPT к своему проекту на Python / Хабр', 'description': '6 декабря Яндекс открыл доступ к своим диалоговым моделям (моделям генерации) и векторного представления текста через API. API уже доступно в Yandex Cloud. Вчера мне потребовалось применить его в...', 'language': 'ru', 'date': '2023-06-01', 'news_name': 'habr'})), GraphDocument(nodes=[Node(id='Default-Service', type='Service')], relationships=[Relationship(source=Node(id='Default-Service', type='Service'), target=Node(id='+ Создать Новый Ключ', type='Action'), type='NAVIGATION'), Relationship(source=Node(id='+ Создать Новый Ключ', type='Action'), target=Node(id='Создать Api-Ключ', type='Action'), type='SELECT_OPTION'), Relationship(source=Node(id='Создать Api-Ключ', type='Action'), target=Node(id='Окно Создания Ключа', type='Window'), type='OPEN_WINDOW')], source=Document(page_content='ае default-service.В меню навигации справа вверху страницы нажмите \"+ Создать новый ключ\". В открывшемся меню выберите \"Создать API-ключ\". Откроется окно создания ключа. Описание может быть любым, но после генерации не закрывайте окно с ключом: его нужно скопировать и сохранить вместе со скопированным ранее идентификатором каталога. Если поспешите закрыть окно, ключ придётся пересоздать.Подготовка завершена.Создаём пример на PythonЯ исхожу из того, что Pythonи среда разработки уже установлены.', metadata={'source': 'https://habr.com/ru/articles/780008/', 'title': 'Как подключить Yandex GPT к своему проекту на Python / Хабр', 'description': '6 декабря Яндекс открыл доступ к своим диалоговым моделям (моделям генерации) и векторного представления текста через API. API уже доступно в Yandex Cloud. Вчера мне потребовалось применить его в...', 'language': 'ru', 'date': '2023-06-01', 'news_name': 'habr'})), GraphDocument(nodes=[Node(id='Ботки', type='Software'), Node(id='Файл Yandexgptdemo.Py', type='File'), Node(id='Requests', type='Library')], relationships=[Relationship(source=Node(id='Ботки', type='Software'), target=Node(id='Файл Yandexgptdemo.Py', type='File'), type='REQUIRES'), Relationship(source=Node(id='Файл Yandexgptdemo.Py', type='File'), target=Node(id='Requests', type='Library'), type='REQUIRES')], source=Document(page_content='ботки уже установлены. Но если их нет, их можно скачать по ссылке и установить. Создайте файл yandexGPTdemo.py следующего содержания:import requests\\n\\nprompt = {\\n    \"modelUri\": \"gpt://<ВАШ_ИДЕНТИФИКАТОР_КАТАЛОГА>/yandexgpt-lite\",\\n    \"completionOptions\": {\\n        \"stream\": False,\\n        \"temperature\": 0.6,\\n        \"maxTokens\": \"2000\"\\n    },\\n    \"messages\": [\\n        {\\n            \"role\": \"system\",\\n            \"text\": \"Ты ассистент дроид, способный помочь в галактических приключениях.\"\\n        },\\n        {\\n            \"role\": \"user\",\\n            \"text\": \"Привет, Дроид! Мне нужна твоя помощь, чтобы узнать', metadata={'source': 'https://habr.com/ru/articles/780008/', 'title': 'Как подключить Yandex GPT к своему проекту на Python / Хабр', 'description': '6 декабря Яндекс открыл доступ к своим диалоговым моделям (моделям генерации) и векторного представления текста через API. API уже доступно в Yandex Cloud. Вчера мне потребовалось применить его в...', 'language': 'ru', 'date': '2023-06-01', 'news_name': 'habr'})), GraphDocument(nodes=[Node(id='Сила', type='Concept'), Node(id='Галактика', type='Concept'), Node(id='Медитация', type='Concept'), Node(id='Световой Меч', type='Concept'), Node(id='Джедай', type='Concept')], relationships=[Relationship(source=Node(id='Сила', type='Concept'), target=Node(id='Галактика', type='Concept'), type='CONNECTS'), Relationship(source=Node(id='Сила', type='Concept'), target=Node(id='Медитация', type='Concept'), type='INVOLVES'), Relationship(source=Node(id='Джедай', type='Concept'), target=Node(id='Световой Меч', type='Concept'), type='USES')], source=Document(page_content=' помощь, чтобы узнать больше о Силе. Как я могу научиться ее использовать?\"\\n        },\\n        {\\n            \"role\": \"assistant\",\\n            \"text\": \"Привет! Чтобы овладеть Силой, тебе нужно понять ее природу. Сила находится вокруг нас и соединяет всю галактику. Начнем с основ медитации.\"\\n        },\\n        {\\n            \"role\": \"user\",\\n            \"text\": \"Хорошо, а как насчет строения светового меча? Это важная часть тренировки джедая. Как мне создать его?\"\\n        }\\n    ]\\n}\\n\\n\\nurl = \"https://llm.api.cloud.yandex.net/foundationModels/v1/completion\"\\nheaders = {\\n    \"Content-Type\": \"application/json\",\\n    \"Author', metadata={'source': 'https://habr.com/ru/articles/780008/', 'title': 'Как подключить Yandex GPT к своему проекту на Python / Хабр', 'description': '6 декабря Яндекс открыл доступ к своим диалоговым моделям (моделям генерации) и векторного представления текста через API. API уже доступно в Yandex Cloud. Вчера мне потребовалось применить его в...', 'language': 'ru', 'date': '2023-06-01', 'news_name': 'habr'}))]\n","output_type":"stream"}]},{"cell_type":"code","source":"graph.add_graph_documents(\n    graph_documents,\n    baseEntityLabel=True,\n    include_source=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T14:39:47.982148Z","iopub.execute_input":"2024-06-10T14:39:47.982537Z","iopub.status.idle":"2024-06-10T14:39:51.199109Z","shell.execute_reply.started":"2024-06-10T14:39:47.982509Z","shell.execute_reply":"2024-06-10T14:39:51.197857Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# directly show the graph resulting from the given Cypher query\ndefault_cypher = \"MATCH (s)-[r:!MENTIONS]->(t) RETURN s,r,t LIMIT 50\"\n\n# def showGraph(cypher: str = default_cypher):\n#     # create a neo4j session to run queries\n#     driver = GraphDatabase.driver(\n#         uri = NEO4J_URI,\n#         auth = (NEO4J_USERNAME,\n#                 NEO4J_PASSWORD))\n#     session = driver.session()\n#     widget = GraphWidget(graph = session.run(cypher).graph())\n#     widget.node_label_mapping = 'id'\n#     display(widget)\n#     return widget\n\n# showGraph()","metadata":{"execution":{"iopub.status.busy":"2024-06-10T11:56:39.059834Z","iopub.execute_input":"2024-06-10T11:56:39.060274Z","iopub.status.idle":"2024-06-10T11:56:39.068250Z","shell.execute_reply.started":"2024-06-10T11:56:39.060242Z","shell.execute_reply":"2024-06-10T11:56:39.066281Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"vector_index = Neo4jVector.from_existing_graph(\n    embeddings,\n    search_type=\"hybrid\",\n    node_label=\"Document\",\n    text_node_properties=[\"text\"],\n    embedding_node_property=\"embedding\",\n    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD\n)\ngraph.query(\n    \"CREATE FULLTEXT INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON EACH [e.id]\")","metadata":{"execution":{"iopub.status.busy":"2024-06-10T14:53:23.788569Z","iopub.execute_input":"2024-06-10T14:53:23.789097Z","iopub.status.idle":"2024-06-10T14:53:40.495883Z","shell.execute_reply.started":"2024-06-10T14:53:23.789058Z","shell.execute_reply":"2024-06-10T14:53:40.494611Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def generate_full_text_query(input: str) -> str:\n    \"\"\"\n    Generate a full-text search query for a given input string.\n\n    This function constructs a query string suitable for a full-text search.\n    It processes the input string by splitting it into words and appending a\n    similarity threshold (~2 changed characters) to each word, then combines\n    them using the AND operator. Useful for mapping entities from user questions\n    to database values, and allows for some misspelings.\n    \"\"\"\n    full_text_query = \"\"\n    words = [el for el in remove_lucene_chars(input).split() if el]\n    for word in words[:-1]:\n        full_text_query += f\" {word}~2 AND\"\n    full_text_query += f\" {words[-1]}~2\"\n    return full_text_query.strip()\n\n# Fulltext index query\ndef structured_retriever(tags) -> str:\n    \"\"\"\n    Collects the neighborhood of entities mentioned\n    in the question\n    \"\"\"\n    result = \"\"\n    for entity in tags:\n        response = graph.query(\n            \"\"\"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\n            YIELD node,score\n            CALL {\n              WITH node\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n              UNION ALL\n              WITH node\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\n            }\n            RETURN output LIMIT 50\n            \"\"\",\n            {\"query\": generate_full_text_query(entity)},\n        )\n        result += \"\\n\".join([el['output'] for el in response])\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-06-10T14:55:27.642158Z","iopub.execute_input":"2024-06-10T14:55:27.642654Z","iopub.status.idle":"2024-06-10T14:55:27.653721Z","shell.execute_reply.started":"2024-06-10T14:55:27.642603Z","shell.execute_reply":"2024-06-10T14:55:27.652495Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"print(structured_retriever(tags))","metadata":{"execution":{"iopub.status.busy":"2024-06-10T14:55:28.867295Z","iopub.execute_input":"2024-06-10T14:55:28.867734Z","iopub.status.idle":"2024-06-10T14:55:29.238434Z","shell.execute_reply.started":"2024-06-10T14:55:28.867700Z","shell.execute_reply":"2024-06-10T14:55:29.237147Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Api - REQUIRES -> Python\nApi Ключ - AUTHORIZATION_METHOD:_API_KEY -> Сервисный Аккаунт\n500 Рублей - AUTHORIZATION_KEY_GENERATION -> Api КлючYandex Gpt Api - USES -> Yandex Cloud\nYandex Gpt - USAGE -> Python\nYandex Gpt - REQUIRES -> Python\nYandex Gpt - REQUIRES -> Yandex Id\nYandex Cloud - REQUIRES -> Yandex GptYandex Gpt - REQUIRES -> Yandex Id\nYandex Cloud - REQUIRES -> Yandex Id\nYandex Gpt - USAGE -> Python\nYandex Gpt - REQUIRES -> Python\nYandex Gpt - REQUIRES -> Yandex Id\nYandex Cloud - REQUIRES -> Yandex Gpt\n","output_type":"stream"}]},{"cell_type":"code","source":"template = \"\"\"You must summarize the news text based only on the following context. Dont write anything else instead of summary:\nStructured data: {context}\n\nText: {text}\nWrite only small summary of news with just main key points. Your summury will be in news digest. Dont write anything instead of summary. \nAnswer in Russian:\"\"\"\nprompt = ChatPromptTemplate.from_template(template)\n\nchain = (\n    RunnableParallel(\n        {\n            \"context\": RunnablePassthrough(),\n            \"text\": RunnablePassthrough(),\n        }\n    )\n    | prompt\n    | llm\n    | StrOutputParser()\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T14:55:56.449897Z","iopub.execute_input":"2024-06-10T14:55:56.450358Z","iopub.status.idle":"2024-06-10T14:55:56.458255Z","shell.execute_reply.started":"2024-06-10T14:55:56.450321Z","shell.execute_reply":"2024-06-10T14:55:56.456854Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def generate_news_digest(news_items):\n    digest = \"\"\n    for el in news_items:\n        news_name = el.metadata['news_name']\n        news_link = el.metadata['source']\n        summary = el.metadata['summary']\n        date = el.metadata['date']\n        \n        digest += f\"{news_name} ({news_link}). {date}:\\n{summary}\\n\\n\"\n    \n    return digest\n\n\ndef retriever(tags: List[str]):\n    question = \"News by tags \"+\", \".join(tags)\n    print(f\"Search query: {question}\")\n    structured_data = structured_retriever(tags)\n    sine = vector_index.similarity_search(question)\n    \n    #reranked_sine=...\n    #for el in reranked_sine:\n    for el in sine:\n        el.metadata['summary'] = chain.invoke({\"text\": el.page_content, \"context\": structured_data})\n    \n    return generate_news_digest(sine)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T14:55:59.992160Z","iopub.execute_input":"2024-06-10T14:55:59.992681Z","iopub.status.idle":"2024-06-10T14:56:00.002549Z","shell.execute_reply.started":"2024-06-10T14:55:59.992639Z","shell.execute_reply":"2024-06-10T14:56:00.001278Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"digest = retriever(tags)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T14:56:02.213286Z","iopub.execute_input":"2024-06-10T14:56:02.213792Z","iopub.status.idle":"2024-06-10T14:56:09.239127Z","shell.execute_reply.started":"2024-06-10T14:56:02.213754Z","shell.execute_reply":"2024-06-10T14:56:09.237835Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Search query: News by tags AI, GPT, Yandex\n","output_type":"stream"}]},{"cell_type":"code","source":"print(digest)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T14:56:09.241063Z","iopub.execute_input":"2024-06-10T14:56:09.241439Z","iopub.status.idle":"2024-06-10T14:56:09.247390Z","shell.execute_reply.started":"2024-06-10T14:56:09.241406Z","shell.execute_reply":"2024-06-10T14:56:09.246124Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"habr (https://habr.com/ru/articles/780008/). 2023-06-01:\nКонечно, вот краткий пересказ текста, основанный на предоставленном контексте, без изменений:\n\nКак подключить GPT от Яндекса к своему Python-проекту: для этого нужен Python, сервисный аккаунт с API-ключом и аккаунт разработчика GPT. Всё это доступно на сервисах Яндекса, таких как Yandex Gpt, Yandex Id, Yandex Cloud и т.д. Без этих инструментов GPT работать не будет.\n\nДля подключения нужны все эти инструменты и аккаунты.\n\nhabr (https://habr.com/ru/articles/780008/). 2023-06-01:\nИз новости можно понять, что автор столкнулся с проблемой применения API в своём приложении и предлагает читателю сэкономить час или два, воспользовавшись пошаговым гайдом. Для этого нужен опыт работы с Яндекс.Cloud, а также ключ доступа.\n\nhabr (https://habr.com/ru/articles/780008/). 2023-06-01:\nДля использования YandexGPT в Python-проектах необходимо создать Яндекс ID, подключить оплату в Yandex Cloud, получить ключ авторизации, идентификатор каталога и создать Python-файл для взаимодействия с API. Первый шаг — создание Яндекс ID. Процедура довольно простая и может быть выполнена по ссылке с помощью регистрации через номер телефона. Всё это необходимо для YandexGPT и Yandex Cloud.\n\nhabr (https://habr.com/ru/articles/780008/). 2023-06-01:\nТекст новости следующий: в статье описывается, как установить программу и использовать YandexGPT, которая позволяет выполнять различные задачи. Для этого необходимо создать файл с определённым содержимым и выполнить некоторые действия.\n\n**Краткое содержание новости:** в статье рассматривается установка программы для использования YandexGPT — сервиса Яндекса, который может выполнять запросы пользователей.\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}